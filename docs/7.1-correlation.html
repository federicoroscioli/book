<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.1 Correlation | Introduction to Data Analysis with R" />
<meta property="og:type" content="book" />




<meta name="author" content="Federico Roscioli" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="7.1 Correlation | Introduction to Data Analysis with R">

<title>7.1 Correlation | Introduction to Data Analysis with R</title>

<script src="book_assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="book_assets/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="book_assets/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="book_assets/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="book_assets/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="book_assets/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface" id="toc-preface">Preface</a></li>
<li><a href="introduction.html#introduction" id="toc-introduction">Introduction</a></li>
<li class="part"><span><b>I The R code</b></span></li>
<li class="has-sub"><a href="1-installation.html#installation" id="toc-installation"><span class="toc-section-number">1</span> Installation</a>
<ul>
<li><a href="1.1-introductory-activities.html#introductory-activities" id="toc-introductory-activities"><span class="toc-section-number">1.1</span> Introductory activities</a></li>
<li><a href="1.2-visualization-suggestions.html#visualization-suggestions" id="toc-visualization-suggestions"><span class="toc-section-number">1.2</span> Visualization suggestions</a></li>
<li><a href="1.3-the-workspace.html#the-workspace" id="toc-the-workspace"><span class="toc-section-number">1.3</span> The workspace</a></li>
</ul></li>
<li class="has-sub"><a href="2-a-b-c.html#a-b-c" id="toc-a-b-c"><span class="toc-section-number">2</span> A, B, C</a>
<ul>
<li><a href="2.1-the-first-code.html#the-first-code" id="toc-the-first-code"><span class="toc-section-number">2.1</span> The first code</a></li>
<li><a href="2.2-indexing.html#indexing" id="toc-indexing"><span class="toc-section-number">2.2</span> Indexing</a></li>
<li><a href="2.3-the-first-function.html#the-first-function" id="toc-the-first-function"><span class="toc-section-number">2.3</span> The first function</a></li>
<li><a href="2.4-dataset-exploration.html#dataset-exploration" id="toc-dataset-exploration"><span class="toc-section-number">2.4</span> Dataset Exploration</a></li>
<li><a href="2.5-subsetting.html#subsetting" id="toc-subsetting"><span class="toc-section-number">2.5</span> Subsetting</a></li>
<li><a href="2.6-importing-and-exporting-data.html#importing-and-exporting-data" id="toc-importing-and-exporting-data"><span class="toc-section-number">2.6</span> Importing and exporting data</a></li>
<li><a href="2.7-exercises.html#exercises" id="toc-exercises"><span class="toc-section-number">2.7</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="3-data-cleaning.html#data-cleaning" id="toc-data-cleaning"><span class="toc-section-number">3</span> Data Cleaning</a>
<ul>
<li><a href="3.1-variable-names.html#variable-names" id="toc-variable-names"><span class="toc-section-number">3.1</span> Variable Names</a></li>
<li class="has-sub"><a href="3.2-variable-types.html#variable-types" id="toc-variable-types"><span class="toc-section-number">3.2</span> Variable Types</a>
<ul>
<li><a href="3.2-variable-types.html#factor-variables" id="toc-factor-variables"><span class="toc-section-number">3.2.1</span> Factor variables</a></li>
<li><a href="3.2-variable-types.html#dates-and-times" id="toc-dates-and-times"><span class="toc-section-number">3.2.2</span> Dates and times</a></li>
</ul></li>
<li><a href="3.3-row-names.html#row-names" id="toc-row-names"><span class="toc-section-number">3.3</span> Row Names</a></li>
</ul></li>
<li class="has-sub"><a href="4-advanced-data-manipulation-and-plotting.html#advanced-data-manipulation-and-plotting" id="toc-advanced-data-manipulation-and-plotting"><span class="toc-section-number">4</span> Advanced Data Manipulation and Plotting</a>
<ul>
<li><a href="4.1-ifelse.html#ifelse" id="toc-ifelse"><span class="toc-section-number">4.1</span> Ifelse</a></li>
<li><a href="4.2-the-apply-family.html#the-apply-family" id="toc-the-apply-family"><span class="toc-section-number">4.2</span> The Apply family</a></li>
<li><a href="4.3-dplyr.html#dplyr" id="toc-dplyr"><span class="toc-section-number">4.3</span> Dplyr</a></li>
<li><a href="4.4-merging-datasets.html#merging-datasets" id="toc-merging-datasets"><span class="toc-section-number">4.4</span> Merging datasets</a></li>
<li><a href="4.5-melting-vs-transposing.html#melting-vs-transposing" id="toc-melting-vs-transposing"><span class="toc-section-number">4.5</span> Melting vs Transposing</a></li>
<li><a href="4.6-ggplot2.html#ggplot2" id="toc-ggplot2"><span class="toc-section-number">4.6</span> Ggplot2</a></li>
<li><a href="4.7-exercises-1.html#exercises-1" id="toc-exercises-1"><span class="toc-section-number">4.7</span> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Statistical Analysis</b></span></li>
<li class="has-sub"><a href="5-exploratory-data-analysis.html#exploratory-data-analysis" id="toc-exploratory-data-analysis"><span class="toc-section-number">5</span> Exploratory Data Analysis</a>
<ul>
<li><a href="5.1-central-tendency-measures.html#central-tendency-measures" id="toc-central-tendency-measures"><span class="toc-section-number">5.1</span> Central Tendency Measures</a></li>
<li><a href="5.2-variability-measures.html#variability-measures" id="toc-variability-measures"><span class="toc-section-number">5.2</span> Variability Measures</a></li>
<li><a href="5.3-inequality-measures.html#inequality-measures" id="toc-inequality-measures"><span class="toc-section-number">5.3</span> Inequality Measures</a></li>
<li><a href="5.4-data-visualization.html#data-visualization" id="toc-data-visualization"><span class="toc-section-number">5.4</span> Data visualization</a></li>
<li><a href="5.5-scaling-data.html#scaling-data" id="toc-scaling-data"><span class="toc-section-number">5.5</span> Scaling data</a></li>
<li><a href="5.6-probability-sampling.html#probability-sampling" id="toc-probability-sampling"><span class="toc-section-number">5.6</span> Probability Sampling</a></li>
<li><a href="5.7-exercises-2.html#exercises-2" id="toc-exercises-2"><span class="toc-section-number">5.7</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="6-hypothesis-testing.html#hypothesis-testing" id="toc-hypothesis-testing"><span class="toc-section-number">6</span> Hypothesis Testing</a>
<ul>
<li><a href="6.1-probability-distributions.html#probability-distributions" id="toc-probability-distributions"><span class="toc-section-number">6.1</span> Probability Distributions</a></li>
<li><a href="6.2-shapiro-wilk-test.html#shapiro-wilk-test" id="toc-shapiro-wilk-test"><span class="toc-section-number">6.2</span> Shapiro-Wilk Test</a></li>
<li><a href="6.3-one-sample-t-test.html#one-sample-t-test" id="toc-one-sample-t-test"><span class="toc-section-number">6.3</span> One-Sample T-Test</a></li>
<li><a href="6.4-unpaired-two-sample-t-test.html#unpaired-two-sample-t-test" id="toc-unpaired-two-sample-t-test"><span class="toc-section-number">6.4</span> Unpaired Two Sample T-Test</a></li>
<li><a href="6.5-mann-whitney-u-test.html#mann-whitney-u-test" id="toc-mann-whitney-u-test"><span class="toc-section-number">6.5</span> Mann Whitney U Test</a></li>
<li><a href="6.6-paired-sample-t-test.html#paired-sample-t-test" id="toc-paired-sample-t-test"><span class="toc-section-number">6.6</span> Paired Sample T-Test</a></li>
<li><a href="6.7-exercises-3.html#exercises-3" id="toc-exercises-3"><span class="toc-section-number">6.7</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="7-bivariate-analysis.html#bivariate-analysis" id="toc-bivariate-analysis"><span class="toc-section-number">7</span> Bivariate Analysis</a>
<ul>
<li><a href="7.1-correlation.html#correlation" id="toc-correlation"><span class="toc-section-number">7.1</span> Correlation</a></li>
<li><a href="7.2-linear-regression.html#linear-regression" id="toc-linear-regression"><span class="toc-section-number">7.2</span> Linear Regression</a></li>
<li><a href="7.3-logistic-regressions.html#logistic-regressions" id="toc-logistic-regressions"><span class="toc-section-number">7.3</span> Logistic Regressions</a></li>
<li><a href="7.4-exercises-4.html#exercises-4" id="toc-exercises-4"><span class="toc-section-number">7.4</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="8-multivariate-analysis.html#multivariate-analysis" id="toc-multivariate-analysis"><span class="toc-section-number">8</span> Multivariate Analysis</a>
<ul>
<li class="has-sub"><a href="8.1-cluster-analysis.html#cluster-analysis" id="toc-cluster-analysis"><span class="toc-section-number">8.1</span> Cluster Analysis</a>
<ul>
<li><a href="8.1-cluster-analysis.html#hierarchical-clustering" id="toc-hierarchical-clustering"><span class="toc-section-number">8.1.1</span> Hierarchical Clustering</a></li>
<li><a href="8.1-cluster-analysis.html#k-means-clustering" id="toc-k-means-clustering"><span class="toc-section-number">8.1.2</span> K-Means clustering</a></li>
<li><a href="8.1-cluster-analysis.html#the-silhouette-plot" id="toc-the-silhouette-plot"><span class="toc-section-number">8.1.3</span> The silhouette plot</a></li>
</ul></li>
<li><a href="8.2-heatmap.html#heatmap" id="toc-heatmap"><span class="toc-section-number">8.2</span> Heatmap</a></li>
<li><a href="8.3-principal-component-analysis.html#principal-component-analysis" id="toc-principal-component-analysis"><span class="toc-section-number">8.3</span> Principal Component Analysis</a></li>
<li><a href="8.4-classification-and-regression-trees.html#classification-and-regression-trees" id="toc-classification-and-regression-trees"><span class="toc-section-number">8.4</span> Classification And Regression Trees</a></li>
<li class="has-sub"><a href="8.5-composite-indicators.html#composite-indicators" id="toc-composite-indicators"><span class="toc-section-number">8.5</span> Composite Indicators</a>
<ul>
<li><a href="8.5-composite-indicators.html#mazziotta-pareto-index" id="toc-mazziotta-pareto-index"><span class="toc-section-number">8.5.1</span> Mazziotta-Pareto Index</a></li>
<li><a href="8.5-composite-indicators.html#adjusted-mazziotta-pareto-index" id="toc-adjusted-mazziotta-pareto-index"><span class="toc-section-number">8.5.2</span> Adjusted Mazziotta-Pareto Index</a></li>
</ul></li>
<li><a href="8.6-exercises-5.html#exercises-5" id="toc-exercises-5"><span class="toc-section-number">8.6</span> Exercises</a></li>
</ul></li>
<li><a href="final-remarks.html#final-remarks" id="toc-final-remarks">Final Remarks</a></li>
<li><a href="bibliography.html#bibliography" id="toc-bibliography">Bibliography</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="correlation" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Correlation</h2>
<p>We will now point our imaginary boat towards the Relationship Islands.
When we see one thing vary, we perceive it changing in some regard, as
the sun setting, the price of goods increasing, or the alternation of
green and red lights at an intersection. Therefore, when two things
covary there are two possibilities. One is that the change in the first
is concomitant with the change in the second, as the change in a child’s
age covaries with his height. The older, the taller. When higher
magnitudes on one thing occur along with higher magnitudes on another
and the lower magnitudes on both also co-occur, then the things vary
together positively, and we denote this situation as positive
covariation or <strong>positive correlation</strong>. The second possibility is that
two things vary inversely or oppositely. That is, the higher magnitudes
of one thing go along with the lower magnitudes of the other and vice
versa. Then, we denote this situation as negative covariation or
<strong>negative correlation</strong>. This seems clear enough, but in order to be
more systematic about correlation more definition is needed.</p>
<p>We start with the concept of <strong>covariance</strong>, which represents the
direction of the linear relationship between two variables. By direction
we mean if the variables are directly proportional or inversely
proportional to each other. Thus, if increasing the value of one
variable we have a positive or a negative impact on the value of the
other variable. The values of covariance can be any number between the
two opposite infinities. It’s important to mention that the covariance
only <u>measures the direction of the relationship between two variables
and not its magnitude</u>, for which the correlation is used.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="7.1-correlation.html#cb51-1" tabindex="-1"></a><span class="co"># simple covariance</span></span>
<span id="cb51-2"><a href="7.1-correlation.html#cb51-2" tabindex="-1"></a><span class="fu">cov</span>(mtcars<span class="sc">$</span>hp, mtcars<span class="sc">$</span>mpg)</span></code></pre></div>
<p>In probability theory and statistics, <strong>correlation</strong>, also called
correlation coefficient, indicates the strength and direction of a
linear relationship between two random variables <span class="citation">(<a href="#ref-davis2021">Davis 2021</a>; <a href="#ref-madhavan2019">Madhavan 2019</a>; <a href="#ref-wilson2014">Wilson 2014</a>)</span>. In general statistical usage, correlation
or co-relation refers to the departure of two variables from
independence. In this broad sense there are several coefficients,
measuring the degree of correlation, adapted to the nature of data. The
best known is the <strong>Pearson</strong> product-moment correlation coefficient
(<span class="math inline">\(\rho\)</span>), which is used for linearly related variables and is obtained
by dividing the covariance of the two variables (<span class="math inline">\(\sigma_{xy}\)</span>) by the
product of their standard deviations (Equation <a href="7.1-correlation.html#eq:pears">(7.1)</a>.</p>
<p><span class="math display" id="eq:pears">\[\begin{equation}
\rho=\frac{\sigma_{xy}}{\sigma_x*\sigma_y}
\tag{7.1}
\end{equation}\]</span></p>
<p>A second measure is the <strong>Spearman</strong>’s rank correlation coefficient
(<span class="math inline">\(\rho_{R(x),R(y)}\)</span>) which is a nonparametric measure of rank
correlation defined as the Pearson correlation coefficient between rank
variables (Equation <a href="7.1-correlation.html#eq:spear">(7.2)</a>).</p>
<p><span class="math display" id="eq:spear">\[\begin{equation}
\rho_{R(x),R(y)}=\frac{cov{(R(x),R(y))}}{\sigma_{R(x)}*\sigma_{R(y)}}
\tag{7.2}
\end{equation}\]</span></p>
<p>While Pearson’s correlation assesses linear relationships, Spearman’s
correlation assesses monotonic relationships (whether linear or not). It
is, thus, fundamental a theoretical assumption taken before choosing the
right measure. Two variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are positively correlated if
when <span class="math inline">\(x\)</span> increases <span class="math inline">\(y\)</span> increases too and when <span class="math inline">\(x\)</span> decreases <span class="math inline">\(y\)</span>
decreases too. The correlation is instead negative when the variable <span class="math inline">\(x\)</span>
increases and the variable <span class="math inline">\(y\)</span> decreases and vice-versa. The sign of
<span class="math inline">\(\rho\)</span> depends only on the covariance (<span class="math inline">\(\sigma_{xy}\)</span>). The correlation
coefficient varies between -1 (perfect negative linear correlation) and
1 (perfect positive linear correlation), and if it is equal to zero the
variables are independent.</p>
<p>The code below allows you to compute the correlation coefficient between
two variables, and then a correlation matrix, which is a table showing
the correlation coefficients between each pair of variables. <em>Note that
the first line of code suppresses the scientific notation, allowing the
results of the future calculation to be expressed in decimals even if
they are really really small (or big) values.</em></p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="7.1-correlation.html#cb52-1" tabindex="-1"></a><span class="co"># suppress scientific notation</span></span>
<span id="cb52-2"><a href="7.1-correlation.html#cb52-2" tabindex="-1"></a><span class="fu">options</span>(<span class="at">scipen =</span> <span class="dv">9999</span>)</span>
<span id="cb52-3"><a href="7.1-correlation.html#cb52-3" tabindex="-1"></a></span>
<span id="cb52-4"><a href="7.1-correlation.html#cb52-4" tabindex="-1"></a><span class="co"># Correlation coefficients</span></span>
<span id="cb52-5"><a href="7.1-correlation.html#cb52-5" tabindex="-1"></a><span class="fu">cor</span>(mtcars<span class="sc">$</span>mpg, mtcars<span class="sc">$</span>disp, <span class="at">method =</span> <span class="st">&quot;pearson&quot;</span>)</span>
<span id="cb52-6"><a href="7.1-correlation.html#cb52-6" tabindex="-1"></a><span class="fu">cor</span>(mtcars<span class="sc">$</span>mpg, mtcars<span class="sc">$</span>disp, <span class="at">method =</span> <span class="st">&quot;spearman&quot;</span>)</span>
<span id="cb52-7"><a href="7.1-correlation.html#cb52-7" tabindex="-1"></a></span>
<span id="cb52-8"><a href="7.1-correlation.html#cb52-8" tabindex="-1"></a><span class="co"># Pearson correlation matrix</span></span>
<span id="cb52-9"><a href="7.1-correlation.html#cb52-9" tabindex="-1"></a><span class="fu">cor</span>(mtcars)</span></code></pre></div>
<p>Because a correlation matrix may result dispersive and difficult to
study, especially when we have a high number of variables, there is the
possibility to visualize it. In fact, if the variables are correlated,
the “scatter” points have a trend very known: if the trend is linear the
correlation is linear.</p>
<p>The code below provides you with some examples. The function <code>pairs()</code>
is internal to R and gives us the most basic graph, while the function
<code>corrplot()</code> belongs to the <code>corrplot</code> package and provides a more
stylish and customizable graph <span class="citation">(<a href="#ref-wei2021">Wei and Simko 2021</a>)</span>. Finally, the most interesting
(but advanced) version of a pair plot is offered by the <code>GGally</code> package
with the function <code>ggpairs()</code><span class="citation">(<a href="#ref-emerson2012">Emerson et al. 2012</a>)</span>. This function allows us to
draw a correlation matrix that can include whatever kind of value or
graph we want inside of each cell.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="7.1-correlation.html#cb53-1" tabindex="-1"></a><span class="co"># basic pair plot</span></span>
<span id="cb53-2"><a href="7.1-correlation.html#cb53-2" tabindex="-1"></a><span class="fu">pairs</span>(cars)</span>
<span id="cb53-3"><a href="7.1-correlation.html#cb53-3" tabindex="-1"></a></span>
<span id="cb53-4"><a href="7.1-correlation.html#cb53-4" tabindex="-1"></a><span class="co"># the corrplot version</span></span>
<span id="cb53-5"><a href="7.1-correlation.html#cb53-5" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span>
<span id="cb53-6"><a href="7.1-correlation.html#cb53-6" tabindex="-1"></a><span class="fu">corrplot</span>(<span class="fu">cor</span>(cars))</span>
<span id="cb53-7"><a href="7.1-correlation.html#cb53-7" tabindex="-1"></a></span>
<span id="cb53-8"><a href="7.1-correlation.html#cb53-8" tabindex="-1"></a><span class="co"># the ggally version</span></span>
<span id="cb53-9"><a href="7.1-correlation.html#cb53-9" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb53-10"><a href="7.1-correlation.html#cb53-10" tabindex="-1"></a><span class="fu">ggpairs</span>(cars)</span></code></pre></div>
<p>The last measure of relationship we will talk about is the <strong>chi-squared
test</strong> (also known as <span class="math inline">\(\chi^2\)</span> test). This is a hypothesis test
statistics that comes into play when dealing with contingency tables and
relatively large sample sizes. In simpler terms, the chi-squared test is
primarily employed to assess whether there’s a relationship between two
<u>categorical variables</u> in terms of their impact on the test
statistic. The purpose of the test is to evaluate how likely the
observed frequencies would be assuming the null hypothesis (<span class="math inline">\(H_0\)</span>) is
true. Test statistics that follow a <span class="math inline">\(\chi^2\)</span> distribution occur when the
observations are independent.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="7.1-correlation.html#cb54-1" tabindex="-1"></a><span class="co"># H0: The two variables are independent.</span></span>
<span id="cb54-2"><a href="7.1-correlation.html#cb54-2" tabindex="-1"></a><span class="co"># H1: The two variables relate to each other.</span></span>
<span id="cb54-3"><a href="7.1-correlation.html#cb54-3" tabindex="-1"></a><span class="fu">chisq.test</span>(mtcars<span class="sc">$</span>cyl, mtcars<span class="sc">$</span>am)</span></code></pre></div>
<p>The code above computes the <span class="math inline">\(\chi^2\)</span> test for the number of cilinders of
a car and the presence of manual transmission. Since we get a p-Value
less than the significance level of 0.05, we reject the null hypothesis
and conclude that the two variables are in fact dependent.</p>
<p><strong>Cramér’s V</strong> (sometimes referred to as Cramer’s <span class="math inline">\(\phi\)</span>). This is a
measure of association between two categorical variables (or
categorical) based on Pearson’s <span class="math inline">\(\chi^2\)</span> statistic and it was published
by Harald Cramér in 1946. Cramér’s V, gives us a method that can be used
when we want to study the intercorrelation between two discrete
variables, and may be used with variables having two or more levels. It
varies from 0 (corresponding to no association between the variables) to
1 (complete association) and can reach 1 only when each variable is
completely determined by the other. Thus <u>it does not tell us the
direction of the association</u>.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="7.1-correlation.html#cb55-1" tabindex="-1"></a><span class="fu">library</span>(DescTools)</span>
<span id="cb55-2"><a href="7.1-correlation.html#cb55-2" tabindex="-1"></a><span class="fu">CramerV</span>(mtcars<span class="sc">$</span>cyl, mtcars<span class="sc">$</span>am)</span></code></pre></div>
<p> </p>
<p> </p>
<p> </p>
</div>
<h3>Bibliography</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-davis2021" class="csl-entry">
Davis, Brittany. 2021. <span>“When Correlation Is Better Than Causation.”</span> <a href="https://towardsdatascience.com/when-correlation-is-better-than-causation-1cbfa2708fbb">https://towardsdatascience.com/when-correlation-is-better-than-causation-1cbfa2708fbb</a>.
</div>
<div id="ref-emerson2012" class="csl-entry">
Emerson, John W., Walton A. Green, Barret Schloerke, Jason Crowley, Dianne Cook, Heike Hofmann, and Hadley Wickham. 2012. <span>“The Generalized Pairs Plot.”</span> <em>Journal of Computational and Graphical Statistics</em> 22 (1): 79–91. <a href="https://doi.org/10.1080/10618600.2012.694762">https://doi.org/10.1080/10618600.2012.694762</a>.
</div>
<div id="ref-madhavan2019" class="csl-entry">
Madhavan, Archana. 2019. <span>“Correlation Vs Causation: Understand the Difference for Your Product.”</span> <a href="https://amplitude.com/blog/causation-correlation">https://amplitude.com/blog/causation-correlation</a>.
</div>
<div id="ref-wei2021" class="csl-entry">
Wei, Taiyun, and Viliam Simko. 2021. <span>“An Introduction to Corrplot Package.”</span> <em>The Comprehensive R Archive Network</em>. <a href="https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html">https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html</a>.
</div>
<div id="ref-wilson2014" class="csl-entry">
Wilson, Mark. 2014. <span>“Hilarious Graphs Prove That Correlation Isn<span>’</span>t Causation.”</span> <a href="https://www.fastcompany.com/3030529/hilarious-graphs-prove-that-correlation-isnt-causation">https://www.fastcompany.com/3030529/hilarious-graphs-prove-that-correlation-isnt-causation</a>.
</div>
</div>
<p style="text-align: center;">
<a href="7-bivariate-analysis.html"><button class="btn btn-default">Previous</button></a>
<a href="7.2-linear-regression.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
