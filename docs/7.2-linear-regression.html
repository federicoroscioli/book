<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="7.2 Linear Regression | Introduction to Data Analysis with R" />
<meta property="og:type" content="book" />




<meta name="author" content="Federico Roscioli" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="7.2 Linear Regression | Introduction to Data Analysis with R">

<title>7.2 Linear Regression | Introduction to Data Analysis with R</title>

<script src="book_assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="book_assets/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="book_assets/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="book_assets/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="book_assets/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="book_assets/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#preface" id="toc-preface">Preface</a></li>
<li><a href="introduction.html#introduction" id="toc-introduction">Introduction</a></li>
<li class="part"><span><b>I The R code</b></span></li>
<li class="has-sub"><a href="1-installation.html#installation" id="toc-installation"><span class="toc-section-number">1</span> Installation</a>
<ul>
<li><a href="1.1-introductory-activities.html#introductory-activities" id="toc-introductory-activities"><span class="toc-section-number">1.1</span> Introductory activities</a></li>
<li><a href="1.2-visualization-suggestions.html#visualization-suggestions" id="toc-visualization-suggestions"><span class="toc-section-number">1.2</span> Visualization suggestions</a></li>
<li><a href="1.3-the-workspace.html#the-workspace" id="toc-the-workspace"><span class="toc-section-number">1.3</span> The workspace</a></li>
</ul></li>
<li class="has-sub"><a href="2-a-b-c.html#a-b-c" id="toc-a-b-c"><span class="toc-section-number">2</span> A, B, C</a>
<ul>
<li><a href="2.1-the-first-code.html#the-first-code" id="toc-the-first-code"><span class="toc-section-number">2.1</span> The first code</a></li>
<li><a href="2.2-indexing.html#indexing" id="toc-indexing"><span class="toc-section-number">2.2</span> Indexing</a></li>
<li><a href="2.3-the-first-function.html#the-first-function" id="toc-the-first-function"><span class="toc-section-number">2.3</span> The first function</a></li>
<li><a href="2.4-dataset-exploration.html#dataset-exploration" id="toc-dataset-exploration"><span class="toc-section-number">2.4</span> Dataset Exploration</a></li>
<li><a href="2.5-subsetting.html#subsetting" id="toc-subsetting"><span class="toc-section-number">2.5</span> Subsetting</a></li>
<li><a href="2.6-importing-and-exporting-data.html#importing-and-exporting-data" id="toc-importing-and-exporting-data"><span class="toc-section-number">2.6</span> Importing and exporting data</a></li>
<li><a href="2.7-exercises.html#exercises" id="toc-exercises"><span class="toc-section-number">2.7</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="3-data-cleaning.html#data-cleaning" id="toc-data-cleaning"><span class="toc-section-number">3</span> Data Cleaning</a>
<ul>
<li><a href="3.1-variable-names.html#variable-names" id="toc-variable-names"><span class="toc-section-number">3.1</span> Variable Names</a></li>
<li class="has-sub"><a href="3.2-variable-types.html#variable-types" id="toc-variable-types"><span class="toc-section-number">3.2</span> Variable Types</a>
<ul>
<li><a href="3.2-variable-types.html#factor-variables" id="toc-factor-variables"><span class="toc-section-number">3.2.1</span> Factor variables</a></li>
<li><a href="3.2-variable-types.html#dates-and-times" id="toc-dates-and-times"><span class="toc-section-number">3.2.2</span> Dates and times</a></li>
</ul></li>
<li><a href="3.3-row-names.html#row-names" id="toc-row-names"><span class="toc-section-number">3.3</span> Row Names</a></li>
</ul></li>
<li class="has-sub"><a href="4-advanced-data-manipulation-and-plotting.html#advanced-data-manipulation-and-plotting" id="toc-advanced-data-manipulation-and-plotting"><span class="toc-section-number">4</span> Advanced Data Manipulation and Plotting</a>
<ul>
<li><a href="4.1-ifelse.html#ifelse" id="toc-ifelse"><span class="toc-section-number">4.1</span> Ifelse</a></li>
<li><a href="4.2-the-apply-family.html#the-apply-family" id="toc-the-apply-family"><span class="toc-section-number">4.2</span> The Apply family</a></li>
<li><a href="4.3-dplyr.html#dplyr" id="toc-dplyr"><span class="toc-section-number">4.3</span> Dplyr</a></li>
<li><a href="4.4-merging-datasets.html#merging-datasets" id="toc-merging-datasets"><span class="toc-section-number">4.4</span> Merging datasets</a></li>
<li><a href="4.5-melting-vs-transposing.html#melting-vs-transposing" id="toc-melting-vs-transposing"><span class="toc-section-number">4.5</span> Melting vs Transposing</a></li>
<li><a href="4.6-ggplot2.html#ggplot2" id="toc-ggplot2"><span class="toc-section-number">4.6</span> Ggplot2</a></li>
<li><a href="4.7-exercises-1.html#exercises-1" id="toc-exercises-1"><span class="toc-section-number">4.7</span> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Statistical Analysis</b></span></li>
<li class="has-sub"><a href="5-exploratory-data-analysis.html#exploratory-data-analysis" id="toc-exploratory-data-analysis"><span class="toc-section-number">5</span> Exploratory Data Analysis</a>
<ul>
<li><a href="5.1-central-tendency-measures.html#central-tendency-measures" id="toc-central-tendency-measures"><span class="toc-section-number">5.1</span> Central Tendency Measures</a></li>
<li><a href="5.2-variability-measures.html#variability-measures" id="toc-variability-measures"><span class="toc-section-number">5.2</span> Variability Measures</a></li>
<li><a href="5.3-inequality-measures.html#inequality-measures" id="toc-inequality-measures"><span class="toc-section-number">5.3</span> Inequality Measures</a></li>
<li><a href="5.4-data-visualization.html#data-visualization" id="toc-data-visualization"><span class="toc-section-number">5.4</span> Data visualization</a></li>
<li><a href="5.5-scaling-data.html#scaling-data" id="toc-scaling-data"><span class="toc-section-number">5.5</span> Scaling data</a></li>
<li><a href="5.6-probability-sampling.html#probability-sampling" id="toc-probability-sampling"><span class="toc-section-number">5.6</span> Probability Sampling</a></li>
<li><a href="5.7-exercises-2.html#exercises-2" id="toc-exercises-2"><span class="toc-section-number">5.7</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="6-hypothesis-testing.html#hypothesis-testing" id="toc-hypothesis-testing"><span class="toc-section-number">6</span> Hypothesis Testing</a>
<ul>
<li><a href="6.1-probability-distributions.html#probability-distributions" id="toc-probability-distributions"><span class="toc-section-number">6.1</span> Probability Distributions</a></li>
<li><a href="6.2-shapiro-wilk-test.html#shapiro-wilk-test" id="toc-shapiro-wilk-test"><span class="toc-section-number">6.2</span> Shapiro-Wilk Test</a></li>
<li><a href="6.3-one-sample-t-test.html#one-sample-t-test" id="toc-one-sample-t-test"><span class="toc-section-number">6.3</span> One-Sample T-Test</a></li>
<li><a href="6.4-unpaired-two-sample-t-test.html#unpaired-two-sample-t-test" id="toc-unpaired-two-sample-t-test"><span class="toc-section-number">6.4</span> Unpaired Two Sample T-Test</a></li>
<li><a href="6.5-mann-whitney-u-test.html#mann-whitney-u-test" id="toc-mann-whitney-u-test"><span class="toc-section-number">6.5</span> Mann Whitney U Test</a></li>
<li><a href="6.6-paired-sample-t-test.html#paired-sample-t-test" id="toc-paired-sample-t-test"><span class="toc-section-number">6.6</span> Paired Sample T-Test</a></li>
<li><a href="6.7-exercises-3.html#exercises-3" id="toc-exercises-3"><span class="toc-section-number">6.7</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="7-bivariate-analysis.html#bivariate-analysis" id="toc-bivariate-analysis"><span class="toc-section-number">7</span> Bivariate Analysis</a>
<ul>
<li><a href="7.1-correlation.html#correlation" id="toc-correlation"><span class="toc-section-number">7.1</span> Correlation</a></li>
<li><a href="7.2-linear-regression.html#linear-regression" id="toc-linear-regression"><span class="toc-section-number">7.2</span> Linear Regression</a></li>
<li><a href="7.3-logistic-regressions.html#logistic-regressions" id="toc-logistic-regressions"><span class="toc-section-number">7.3</span> Logistic Regressions</a></li>
<li><a href="7.4-exercises-4.html#exercises-4" id="toc-exercises-4"><span class="toc-section-number">7.4</span> Exercises</a></li>
</ul></li>
<li class="has-sub"><a href="8-multivariate-analysis.html#multivariate-analysis" id="toc-multivariate-analysis"><span class="toc-section-number">8</span> Multivariate Analysis</a>
<ul>
<li class="has-sub"><a href="8.1-cluster-analysis.html#cluster-analysis" id="toc-cluster-analysis"><span class="toc-section-number">8.1</span> Cluster Analysis</a>
<ul>
<li><a href="8.1-cluster-analysis.html#hierarchical-clustering" id="toc-hierarchical-clustering"><span class="toc-section-number">8.1.1</span> Hierarchical Clustering</a></li>
<li><a href="8.1-cluster-analysis.html#k-means-clustering" id="toc-k-means-clustering"><span class="toc-section-number">8.1.2</span> K-Means clustering</a></li>
<li><a href="8.1-cluster-analysis.html#the-silhouette-plot" id="toc-the-silhouette-plot"><span class="toc-section-number">8.1.3</span> The silhouette plot</a></li>
</ul></li>
<li><a href="8.2-heatmap.html#heatmap" id="toc-heatmap"><span class="toc-section-number">8.2</span> Heatmap</a></li>
<li><a href="8.3-principal-component-analysis.html#principal-component-analysis" id="toc-principal-component-analysis"><span class="toc-section-number">8.3</span> Principal Component Analysis</a></li>
<li><a href="8.4-classification-and-regression-trees.html#classification-and-regression-trees" id="toc-classification-and-regression-trees"><span class="toc-section-number">8.4</span> Classification And Regression Trees</a></li>
<li class="has-sub"><a href="8.5-composite-indicators.html#composite-indicators" id="toc-composite-indicators"><span class="toc-section-number">8.5</span> Composite Indicators</a>
<ul>
<li><a href="8.5-composite-indicators.html#mazziotta-pareto-index" id="toc-mazziotta-pareto-index"><span class="toc-section-number">8.5.1</span> Mazziotta-Pareto Index</a></li>
<li><a href="8.5-composite-indicators.html#adjusted-mazziotta-pareto-index" id="toc-adjusted-mazziotta-pareto-index"><span class="toc-section-number">8.5.2</span> Adjusted Mazziotta-Pareto Index</a></li>
</ul></li>
<li><a href="8.6-exercises-5.html#exercises-5" id="toc-exercises-5"><span class="toc-section-number">8.6</span> Exercises</a></li>
</ul></li>
<li><a href="final-remarks.html#final-remarks" id="toc-final-remarks">Final Remarks</a></li>
<li><a href="bibliography.html#bibliography" id="toc-bibliography">Bibliography</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="linear-regression" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Linear Regression</h2>
<p>Linear regression examines the relation of a dependent variable
(response variable) to specified independent variables (explanatory
variables). The mathematical model of their relationship is the
regression equation. The dependent variable is modelled as a random
variable because of uncertainty as to its value, given only the value of
each independent variable. A regression equation contains estimates of
one or more hypothesized regression parameters (“constants”). These
estimates are constructed using data for the variables, such as from a
sample. The estimates measure the relationship between the dependent
variable and each of the independent variables. They also allow
estimating the value of the dependent variable for a given value of each
respective independent variable.</p>
<p>Uses of regression include curve fitting, prediction (including
forecasting of time-series data), modelling of causal relationships, and
testing scientific hypotheses about relationships between variables.
However, we must always keep in mind that a <strong>correlation does not imply
causation</strong>. In fact, the study of causality is as concerned with the
study of potential causal mechanisms as it is with variation amongst the
data <span class="citation">(<a href="#ref-Imbens2015">Imbens and Rubin 2015</a>)</span>.</p>
<p>The difference between correlation and regression is that whether in the
first <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are on the same level, in the latter one <span class="math inline">\(x\)</span> affect
<span class="math inline">\(y\)</span>, but not the other way around. This has important theoretical
implications in the selection of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. The general form of a
<strong>simple linear regression</strong> is <a href="7.2-linear-regression.html#eq:slr">(7.3)</a>:</p>
<p><span class="math display" id="eq:slr">\[\begin{equation}
y=\beta_0+\beta_1x+e
\tag{7.3}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\beta_0\)</span> is the intercept, <span class="math inline">\(\beta_1\)</span> is the slope, and<span class="math inline">\(e\)</span> is the
error term, which picks up the unpredictable part of the dependent
variable <span class="math inline">\(y\)</span>. We will sometimes describe 1.1 by saying that we are
regressing <span class="math inline">\(y\)</span> on <span class="math inline">\(x\)</span>. The error term <span class="math inline">\(e\)</span> is usually posited to be
normally distributed. The <span class="math inline">\(x\)</span>’s and <span class="math inline">\(y\)</span>’s are the data quantities from
the sample or population in question, and <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are
the unknown parameters (“constants”) to be estimated from the data.
Estimates for the values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> can be derived by
the method of <u>ordinary least squares</u>. The method is called
“least squares”, because estimates of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> minimize
the sum of squared error estimates for the given data set (Equation <a href="7.2-linear-regression.html#eq:rss">(7.4)</a>), thus
minimizing:</p>
<p><span class="math display" id="eq:rss">\[\begin{equation}
RSS=e_1^2+e_2^2+...+e_n^2
\tag{7.4}
\end{equation}\]</span></p>
<p>The estimates are often denoted by <span class="math inline">\(\hat\beta_0\)</span> and <span class="math inline">\(\hat\beta_1\)</span> or
their corresponding Roman letters. It can be shown that least squares
estimates are given by</p>
<p><span class="math display">\[\begin{equation}
\hat\beta_1=\frac{\sum_{i=1}^N(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^N(x_i-\bar{x})^2} \\
\hat\beta_0=\bar{y}-\hat\beta_1 \bar{x}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\bar{x}\)</span> is the mean (average) of the <span class="math inline">\(x\)</span> values and <span class="math inline">\(\bar{y}\)</span>
is the mean of the <span class="math inline">\(y\)</span> values.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-74"></span>
<img src="_main_files/figure-html/unnamed-chunk-74-1.png" alt="Plot of the residuals from a regression line." width="50%"  />
<p class="caption">
Figure 7.1: Plot of the residuals from a regression line.
</p>
</div>
<p>As we said, before building our first regression model, it is important
to have an idea about the theoretical relationship between the variable
we want to study. In the case of the dataset <code>cars</code>, we know that speed
has an impact on the breaking distance of a car (variable dist) from our
physics studies. We can thus say that dist is our dependent variable
(<span class="math inline">\(y\)</span>), and speed is our independent variable (<span class="math inline">\(x\)</span>).</p>
<p>We can fit the model in the following way. Inside the <code>lm()</code> function
place the dependent variable ~ independent variable, comma the dataset
in which they are contained. <em>Note that the formula 1.1 in the <code>lm()</code>
function is written as <code>y ~ x</code>.</em><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> The code chunk below draws a
summary and the plot of the relationship between the speed of a car and
the breaking distance.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="7.2-linear-regression.html#cb56-1" tabindex="-1"></a><span class="co"># linear regression</span></span>
<span id="cb56-2"><a href="7.2-linear-regression.html#cb56-2" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(dist <span class="sc">~</span> speed, <span class="at">data =</span> cars)</span>
<span id="cb56-3"><a href="7.2-linear-regression.html#cb56-3" tabindex="-1"></a><span class="fu">summary</span>(fit)</span>
<span id="cb56-4"><a href="7.2-linear-regression.html#cb56-4" tabindex="-1"></a></span>
<span id="cb56-5"><a href="7.2-linear-regression.html#cb56-5" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb56-6"><a href="7.2-linear-regression.html#cb56-6" tabindex="-1"></a><span class="fu">ggplot</span>(cars, <span class="fu">aes</span>(dist, speed))<span class="sc">+</span></span>
<span id="cb56-7"><a href="7.2-linear-regression.html#cb56-7" tabindex="-1"></a>        <span class="fu">geom_point</span>(<span class="at">size=</span><span class="dv">3</span>)<span class="sc">+</span></span>
<span id="cb56-8"><a href="7.2-linear-regression.html#cb56-8" tabindex="-1"></a>        <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">&quot;lm&quot;</span>)</span></code></pre></div>
<p>The output of the summary of our regression model (Figure 15) must be
read in the following way in order to have a brief idea on the model
that we built. The first step is to look at the Multiple R-squared, this
number tells us which percentage of the data is explained by the model
(65.1% in this case), and thus how significant our model is. If the
model has an appreciable power to explain our data, we then analyze the
coefficients’ estimates and their significance level. We see here that
speed has a p-value lower than 0.001 (thus highly significant<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a>) and
that one unit increase in speed means 3.9 units of increase in distance.
However, there is also a slightly significant intercept, <span class="math inline">\(\beta_0\)</span>,
which means that there are factors which are not present in the model
and that could further explain the behavior of our dependent variable.
From a theoretical perspective this makes sense, in fact, the type of
tires, the weight of the car, the weather conditions (etc..) are some
additional factors that are missing in our model and could improve our
understanding of the phenomenon.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-76"></span>
<img src="images/Schermata%202022-07-07%20alle%2017.24.44.png" alt="Linear regression model summary output." width="50%"  />
<p class="caption">
Figure 7.2: Linear regression model summary output.
</p>
</div>
<p>Whether simple linear regression is a useful approach for predicting a
response on the basis of one single independent variable, we often have
more than one independent variable (<span class="math inline">\(x\)</span>) that influence the dependent
variable (<span class="math inline">\(y\)</span>). Instead of fitting a separate simple linear regression
model for each <span class="math inline">\(x\)</span>, a better approach is to extend the simple linear
regression model. We can do this by giving each independent variable
(<span class="math inline">\(x\)</span>) a separate slope coefficient in a single model. In general,
suppose that we have <span class="math inline">\(p\)</span> distinct independent variables (<span class="math inline">\(x\)</span>). Then the
<strong>multiple linear regression model</strong> takes the form <a href="7.2-linear-regression.html#eq:mlr">(7.5)</a>:</p>
<p><span class="math display" id="eq:mlr">\[\begin{equation}
y\approx\beta_0+\beta_1x_1+\beta_2x_2...+\beta_px_p+e
\tag{7.5}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(x_p\)</span> represents the <span class="math inline">\(p^{th}\)</span> independent variable, and <span class="math inline">\(\beta_p\)</span>
quantifies the association between that variable and the dependent
variable <span class="math inline">\(y\)</span>. We interpret <span class="math inline">\(\beta_p\)</span> as the average effect on <span class="math inline">\(y\)</span> of a
one unit increase in <span class="math inline">\(x_p\)</span>, <u>holding all other independent variables
fixed</u>. In other words, we will still have the effect of the
increase of one independent variable (<span class="math inline">\(x\)</span>) over our dependent variable
(<span class="math inline">\(y\)</span>), but “controlling” for other factors.</p>
<p>In order to include more independent variables into our model, we use
the plus sign. The formula in R will then be <code>y ~ x1 + x2 + x3</code>. If we
want to use all the variables present in our dataset as independent
variables, the formula in R will be <code>y ~ .</code> where the dot stands for
“everything else”. Another possibility is to have an interaction term.
An interaction effect exists when the effect of an independent variable
on a dependent variable changes, depending on the value(s) of one or
more other independent variables (i.e. <span class="math inline">\(y=x*z\)</span>). However, interaction
terms are out of the scope of this manual.</p>
<p>To make an example, we can use the dataset <code>swiss</code>, which reports Swiss
fertility and socioeconomic data from the year 1888. Following some
models with a different number of variables used.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="7.2-linear-regression.html#cb57-1" tabindex="-1"></a><span class="co"># multiple linear regression</span></span>
<span id="cb57-2"><a href="7.2-linear-regression.html#cb57-2" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Fertility <span class="sc">~</span> ., <span class="at">data =</span> swiss)</span>
<span id="cb57-3"><a href="7.2-linear-regression.html#cb57-3" tabindex="-1"></a><span class="fu">summary</span>(fit2)</span>
<span id="cb57-4"><a href="7.2-linear-regression.html#cb57-4" tabindex="-1"></a></span>
<span id="cb57-5"><a href="7.2-linear-regression.html#cb57-5" tabindex="-1"></a>fit3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Fertility <span class="sc">~</span> Education <span class="sc">+</span> Agriculture, <span class="at">data =</span> swiss)</span>
<span id="cb57-6"><a href="7.2-linear-regression.html#cb57-6" tabindex="-1"></a><span class="fu">summary</span>(fit3)</span></code></pre></div>
<p>When we perform multiple linear regression, we are usually interested in
answering a few important questions in order to reach our goal: find the
model, with the lower number of independent variables that best explains
the outcome. The questions are:</p>
<ol style="list-style-type: decimal">
<li><p>Is at least one of the <span class="math inline">\(x_1, x_2, . . . ,x_p\)</span> useful in explaining
the independent variable <span class="math inline">\(y\)</span>?</p></li>
<li><p>Do all the <span class="math inline">\(x_1, x_2, . . . ,x_p\)</span> help to explain <span class="math inline">\(y\)</span>, or is only a
subset of them sufficient?</p></li>
<li><p>How well does the model fit the data?</p></li>
</ol>
<p>In order to answer the questions above we need to do a comparative
analysis between the models. Analysis of Variance (<strong>ANOVA</strong>) consists
of calculations that provide information about levels of variability
within a regression model and form a basis for tests of significance. We
can thus use the function <code>anova()</code> in order to compare multiple
regression models. When ANOVA is applied in practice, it actually
becomes a variable selection method: if the full model is significantly
different (null hypothesis rejected), the variable/s added by the full
model is/are considered useful for prediction. <em>Statistic textbooks
generally recommend to test every predictor for significance.</em></p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="7.2-linear-regression.html#cb58-1" tabindex="-1"></a><span class="co"># ANOVA testing</span></span>
<span id="cb58-2"><a href="7.2-linear-regression.html#cb58-2" tabindex="-1"></a><span class="fu">anova</span>(fit2, fit3)</span></code></pre></div>
<p> </p>
<p> </p>
<p> </p>
</div>
<h3>Bibliography</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Imbens2015" class="csl-entry">
Imbens, Guido W, and Donald B Rubin. 2015. <em>Causal Inference in Statistics, Social, and Biomedical Sciences</em>. Cambridge University Press.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>In order to type the symbol ~ (tilde) it is needed a different
combination of keys according to the operating system and the
keyboards.<a href="7.2-linear-regression.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>For a discussion on the meaning of p-value go back to the previous
chapter.<a href="7.2-linear-regression.html#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="7.1-correlation.html"><button class="btn btn-default">Previous</button></a>
<a href="7.3-logistic-regressions.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
